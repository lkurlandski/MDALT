"""
Run active learning experiments for text classification.
"""

from argparse import ArgumentParser
import os
from pathlib import Path
from pprint import pprint
import random
import sys
from typing import Optional

RAWBYTECLF = Path("/home/lk3591/Documents/code/RawByteClf")
RAWBYTECLFOUTPUT = RAWBYTECLF / "output/SentencePieceBPE/4102/1000/"

sys.path.insert(0, ".")
sys.path.insert(1, RAWBYTECLF.as_posix())
sys.path.insert(2, (RAWBYTECLF / "src").as_posix())

from datasets import concatenate_datasets, DatasetDict
import evaluate
import numpy as np
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    DataCollator,
    DataCollatorWithPadding,
    EarlyStoppingCallback,
    logging,
    PreTrainedModel,
    PreTrainedTokenizerBase,
    Trainer,
    TrainingArguments,
)
import torch
from tqdm import tqdm

from mdalth.analysis import Analyzer
from mdalth.cfg import BR
from mdalth.helpers import IOHelper, Pool
from mdalth.learning import validate, Config, IOHelper, Learner, Evaluator, TrainerFactory

from src.tokenization import get_fast_tokenizer
from src.train import compute_metrics, get_config_hf


parser = ArgumentParser()
parser.add_argument("--learn", action="store_true")
parser.add_argument("--evaluate", action="store_true")
parser.add_argument("--analyze", action="store_true")
parser.add_argument(
    "--dataset_dir",
    type=str, 
    default=(RAWBYTECLFOUTPUT / "10000/clf/1.0/dataset/").as_posix(),
)
parser.add_argument(
    "--pretrained_model_name_or_path",
    type=str,
    default=(RAWBYTECLFOUTPUT / "10000/mlm/1.0/longformer/mlm/best/").as_posix(),
)
parser.add_argument(
    "--tokenizer_file",
    type=str,
    default=(RAWBYTECLFOUTPUT / "vocab.json").as_posix(),
)
parser.add_argument("--max_length", type=int, default=10000)
parser.add_argument("--seed", type=int, default=0)
parser.add_argument("--verbosity", type=int, choices=[10, 20, 30, 40, 50], default=logging.WARNING)
args = parser.parse_args()


LEARN = args.learn
EVALUATE = args.evaluate
ANALYZE = args.analyze
DATASET_DIR = args.dataset_dir
PRETRAINED_MODEL_NAME_OR_PATH = args.pretrained_model_name_or_path
TOKENIZER_FILE = args.tokenizer_file
MAX_LENGTH = args.max_length
SEED = args.seed
VERBOSITY = args.verbosity


random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)


tokenizer = get_fast_tokenizer(TOKENIZER_FILE, MAX_LENGTH)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)
dataset = DatasetDict.load_from_disk(DATASET_DIR)
dataset["tr"] = concatenate_datasets([dataset["tr"], dataset["vl"]])
dataset["tr"].info.features["label"].num_classes = 10
dataset["ts"].info.features["label"].num_classes = 10
model_config = get_config_hf(
    PRETRAINED_MODEL_NAME_OR_PATH,
    num_labels=dataset["tr"].features["label"].num_classes,
)


def model_init() -> PreTrainedModel:
    return AutoModelForSequenceClassification.from_config(model_config)


training_args = TrainingArguments(
    output_dir="/tmp/PLACEHOLDER_WILL_BE_SET_BY_CONFIG",
    learning_rate=1e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=100,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    save_total_limit=2,
    optim="adamw_torch",
)

callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]

pool = Pool(dataset["tr"])
al_config = Config(n_rows=dataset["tr"].num_rows, n_start=50, n_query=50)
io_helper = IOHelper(Path("./output"), overwrite=True)
trainer_fact = TrainerFactory(
    model_init=model_init,
    args=training_args,
    data_collator=data_collator,
    tokenizer=tokenizer,
    callbacks=callbacks,
    compute_metrics=compute_metrics,
)

print(f"{dataset=}\n", BR)
print(f"{data_collator=}\n", BR)
print(f"{tokenizer=}\n", BR)
print(f"{callbacks=}\n", BR)
print(f"{training_args=}\n", BR)
print(f"{model_config=}\n", BR)
print(f"{model_init()=}\n", BR)
print(f"{al_config=}\n", BR)
print(f"{pool=}\n", BR)
print(f"{io_helper=}\n", BR)
print(flush=True)


os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "true"

logging.set_verbosity(VERBOSITY)

if LEARN:
    learner = Learner(pool, al_config, io_helper, trainer_fact)
    learner = learner()
    for model, train_output in tqdm(learner):
        ...

if EVALUATE:
    evaluator = Evaluator(trainer_fact, dataset["ts"], io_helper)
    evaluator = evaluator()
    for model, results in tqdm(evaluator):
        ...

if ANALYZE:
    analyzer = Analyzer(io_helper)
    fig, ax = analyzer()
    fig.savefig(io_helper.learning_curve_path, dpi=400)
